{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subclassing and custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Model subclassing](#coding_tutorial_1)\n",
    " #### [2. Custom layers](#coding_tutorial_2)\n",
    " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
    " #### [4. Custom training loops](#coding_tutorial_4)\n",
    " #### [5. tf.function decorator](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        self.dropout = Dropout(0.4)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.dense_1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        self.dense_3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.dense_1(inputs)\n",
    "        y1 = self.dense_2(inputs)\n",
    "        y2 = self.dense_3(y1)\n",
    "        concat = concatenate([x, y2])\n",
    "        return self.softmax(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  55        \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1, 10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0.04377874 -0.02910187 -0.05243861]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[ 0.00099039,  0.05701539, -0.04537537],\n",
      "       [ 0.1099512 , -0.01502685, -0.06811612],\n",
      "       [-0.08481363, -0.04934097,  0.02709146],\n",
      "       [-0.01326211, -0.02204172, -0.00587505],\n",
      "       [ 0.03091289,  0.00029228,  0.03983648]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Create a custom layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        # you have to create weights and init bias withn the init method\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units,),\n",
    "                                initializer='zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)\n",
    "x = tf.ones((1, 5))\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify trainable weights\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        # you have to create weights and init bias withn the init method\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=False)\n",
    "        self.b = self.add_weight(shape=(units,),\n",
    "                                initializer='zeros',\n",
    "                                trainable=False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 0\n",
      "non-trainable weights: 2\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "\n",
    "class MyLayerMean(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        # you have to create weights and init bias withn the init method\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units,),\n",
    "                                initializer='zeros')\n",
    "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
    "                                         trainable=False)\n",
    "        self.number_call = tf.Variable(initial_value=0,\n",
    "                                         trainable=False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        activations = tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
    "        self.number_call.assign_add(inputs.shape[0])\n",
    "        return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
    "    \n",
    "dense_layer = MyLayerMean(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04545196 0.0981116  0.03240534]\n"
     ]
    }
   ],
   "source": [
    "# Test the layer\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "                \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.02318953 0.02278275 0.01271551 0.03258999 0.02167537 0.02649963\n",
      "  0.02009669 0.01792023 0.01606869 0.02369826 0.0155275  0.0307597\n",
      "  0.01927561 0.01627242 0.02387559 0.01949123 0.01602011 0.05401556\n",
      "  0.01551681 0.03107979 0.02788348 0.00981843 0.01762228 0.03571402\n",
      "  0.00983779 0.01879983 0.01822416 0.01903195 0.02868482 0.00804851\n",
      "  0.01665999 0.01103265 0.032607   0.0106835  0.01120678 0.02163889\n",
      "  0.03742057 0.01964745 0.01906758 0.02784041 0.03469355 0.02327734\n",
      "  0.02444956 0.01395351 0.02611736 0.01696765]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_7 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_2 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_8 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_3 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_9 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 0\n",
      "Non-trainable params: 647,214\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a model object\n",
    "\n",
    "model = MyModel(64,10000,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4448007b38>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEPdJREFUeJzt3W2IpeV9x/HvL6vbpmirxEmw6243bfNUSozJpDq1pZNsaVQoEsiLkqBEEpaQBxR8YfFF+sIX2xCwabDJIlrSgBBK3CYm5AGxTlLJaDu7bFzXIWEbiRGFrHnSRuh2139fnLM4jrN77tk9T3PN9wPDmXPONWf+e83sb675z3Xfd6oKSVJbXjXpAiRJw2e4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhp0zqQ+8UUXXVQ7d+6c1KeXpA1p//79z1bVzKBxEwv3nTt3srS0NKlPL0kbUpIfdxlnW0aSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpFNYXIQ9e3q3G83E9rlL0jAtLsLCAszPw9zccF5v1y44dgy2boUHHhjO647LwHBP8pvAd4Hf6I//clX93aoxAf4RuAZ4AfhgVR0YfrmS9EqjCOKFhd7rnTjRu11Y2Fjh3qUt87/Au6vqUuBtwFVJrlg15mrgDf233cDnh1qlJJ3GWkF8tubnez8otmzp3c7Pn/1rwvhaPQNX7lVVwP/0757bf6tVw64Fvtgf+3CSC5JcXFXPDLVaSVrDySA+uXIfRhDPzfV+A9iorZ5OPfckW4D9wB8C/1RVj6wasg34yYr7T/UfM9wljdwogvjk6w4zfMfZ6ukU7lV1AnhbkguAf0vyx1X12IohWevDVj+QZDe9tg07duw4g3IlaW3DDuJRGMVvGKeyrq2QVfVLYAG4atVTTwHbV9y/BHh6jY+/s6pmq2p2ZmbgGSslqSknf8O47bbR777psltmBvi/qvplklcDfwl8atWw+4CPJ/kScDnwK/vtkvTKLZrj+g2jS1vmYuBf+n33VwH/WlVfT/IRgKraC3yD3jbII/S2Qt4wonolacOY5F75LrtlHgUuW+PxvSveL+Bjwy1Nkja2Se6V9/QDkjQio9or34WnH5CkERnVFs0uDHdJGqFJbdG0LSNJDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S5p6i4uwZ0/vVt14PndJU22S1yHdyFy5S5pqa12HVIMZ7pKm2iSvQ7qR2ZaRNNUmeR3SjcxwlzT1JnUd0o3MtowkNchwl6QGGe6S1CDDXZIaNDDck2xP8mCS5SSHk9y4xpjfSfK1JN/vj7lhNOVKkrroslvmOHBzVR1Icj6wP8n9VfX4ijEfAx6vqr9OMgP8IMk9VXVsFEVLkk5v4Mq9qp6pqgP9958HloFtq4cB5ycJcB7wc3o/FCRJE7CunnuSncBlwCOrnroDeAvwNHAIuLGqXlzj43cnWUqydPTo0TMqWJI0WOdwT3IecC9wU1U9t+rp9wAHgd8F3gbckeS3V79GVd1ZVbNVNTszM3MWZUuSTqdTuCc5l16w31NV+9YYcgOwr3qOAE8Abx5emZKk9eiyWybA3cByVd1+imFPArv6418HvAn40bCKlCStT5fdMlcC1wGHkhzsP3YrsAOgqvYCtwFfSHIICHBLVT07gnolSR0MDPeqeoheYJ9uzNPAXw2rKEnS2fEIVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJY7O4CHv29G41Wl1OPyBJZ21xEXbtgmPHYOtWeOABmJubdFXtcuUuaSwWFnrBfuJE73ZhYdIVtc1wlzQW8/O9FfuWLb3b+flJV9Q22zKSxmJurteKWVjoBbstmdEy3CWNzdycoT4utmUkqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEvakDyVwem5FVLShuOpDAZz5S5pw/FUBoMZ7pI2HE9lMJhtGUkbjqcyGMxwl7QheSqD07MtI0kNGhjuSbYneTDJcpLDSW48xbj5JAf7Y74z/FIlSV11acscB26uqgNJzgf2J7m/qh4/OSDJBcDngKuq6skkrx1RvZKkDgau3Kvqmao60H//eWAZ2LZq2PuBfVX1ZH/cT4ddqCSpu3X13JPsBC4DHln11BuBC5MsJNmf5PrhlCepNR5ZOh6dd8skOQ+4F7ipqp5b43XeAewCXg0sJnm4qn646jV2A7sBduzYcTZ1S9qAPLJ0fDqt3JOcSy/Y76mqfWsMeQr4VlX9uqqeBb4LXLp6UFXdWVWzVTU7MzNzNnVLOkOTXDl7ZOn4DFy5JwlwN7BcVbefYthXgTuSnANsBS4H/mFoVUoaikmvnE8eWXry83tk6eh0actcCVwHHEpysP/YrcAOgKraW1XLSb4FPAq8CNxVVY+NomBJZ26tlfM4w90jS8dnYLhX1UNAOoz7NPDpYRQlaTSmYeXskaXj4ekHpE3ElfPmYbhLm4wr583Bc8tIUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4b5JLS7Cnj29Ww2Xc6tp4DVUN6HFRdi1C44dg61bexdM9pqaw+Hcalq4ct+EFhZ64XPiRO92YWHSFbXDudW0MNw3ofn53qpyy5be7fz8pCtqh3OraWFbZhOam+u1CxYWeuFj22B4nFtNi1TVRD7x7OxsLS0tTeRzS9JGlWR/Vc0OGjewLZNke5IHkywnOZzkxtOMfWeSE0net96CJUnD06Utcxy4uaoOJDkf2J/k/qp6fOWgJFuATwHfHkGdkqR1GLhyr6pnqupA//3ngWVg2xpDPwHcC/x0qBVKktZtXbtlkuwELgMeWfX4NuC9wN5hFSZJOnOdwz3JefRW5jdV1XOrnv4McEtVnRjwGruTLCVZOnr06PqrlQbw6FCpp9NumSTnAl8Hvl1Vt6/x/BNA+ncvAl4AdlfVV071mu6W0bB5dKg2g2HulglwN7C8VrADVNXrq2pnVe0Evgx89HTBLo2CR4dKL+myW+ZK4DrgUJKD/cduBXYAVJV9dk2Fk0eHnly5e3SoNrOB4V5VD/FSy2Wgqvrg2RQknSmPDpVe4ukH1JS5OUNdAk8cJklNMtzVJLdEarOzLaPmuCVScuWuBrklUjLc1SAvmCHZllGD3BIpGe5qlFsitdnZlpGkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3DYVXPpKmi2eF1FnzykfS9HHlrrPmlY+k6WO466x55SNp+tiWWWVx0Sv4rNewr3zk10A6e4b7CvaOz9ywrnzk10AaDtsyK9g7njy/BtJwDAz3JNuTPJhkOcnhJDeuMeYDSR7tv30vyaWjKXe07B1Pnl8DaTi6tGWOAzdX1YEk5wP7k9xfVY+vGPME8BdV9YskVwN3ApePoN6RGnbvWOvn10AajlTV+j4g+SpwR1Xdf4rnLwQeq6ptp3ud2dnZWlpaWtfnlqTNLsn+qpodNG5dPfckO4HLgEdOM+xDwDdP8fG7kywlWTp69Oh6PrUkaR06h3uS84B7gZuq6rlTjHkXvXC/Za3nq+rOqpqtqtmZmZkzqVeS1EGnrZBJzqUX7PdU1b5TjHkrcBdwdVX9bHglSpLWq8tumQB3A8tVdfspxuwA9gHXVdUPh1uiJGm9uqzcrwSuAw4lOdh/7FZgB0BV7QU+CbwG+FzvZwHHuzT8JUmjMTDcq+ohIAPGfBj48LCKkiSdHY9QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3IdkcRH27OndStKkeSWmIfDqQZKmjSv3IfDqQZKmjeE+BF49SNK0sS0zBF49SNK0ceUuSQ1y5T4E/kFV0rRx5T4E/kFV0rQx3IfAP6hKmja2ZYbAP6hKmjaG+5DMzRnqkqaHbRlJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQwHBPsj3Jg0mWkxxOcuMaY5Lks0mOJHk0ydtHU64kqYsupx84DtxcVQeSnA/sT3J/VT2+YszVwBv6b5cDn+/fSpImYODKvaqeqaoD/fefB5aBbauGXQt8sXoeBi5IcvHQq5UkdbKunnuSncBlwCOrntoG/GTF/ad45Q8ASdKYdA73JOcB9wI3VdVzq59e40NqjdfYnWQpydLRo0fXV6kkqbNO4Z7kXHrBfk9V7VtjyFPA9hX3LwGeXj2oqu6sqtmqmp2ZmTmTeiVJHXTZLRPgbmC5qm4/xbD7gOv7u2auAH5VVc8MsU5J0jp02S1zJXAdcCjJwf5jtwI7AKpqL/AN4BrgCPACcMPwS5UkdTUw3KvqIdbuqa8cU8DHhlWUJOnseISqJDXIcJekBhnuktQgw12SGrThwn1xEfbs6d1KktbWZSvk1FhchF274Ngx2LoVHngA5uYmXZUkTZ8NtXJfWOgF+4kTvduFhUlXJEnTaUOF+/x8b8W+ZUvvdn5+0hVJ0nTaUG2ZubleK2ZhoRfstmQkaW0bKtyhF+iGuiSd3oZqy5wNd9lI2kw23Mr9TLjLRtJmsylW7u6ykbTZbIpwd5eNpM1mU7Rl3GUjabPZFOEO7rKRtLlsiraMJG02hrskNchwl6QGGe6S1CDDXZIaZLhLUoNSVZP5xMlR4Mfr+JCLgGdHVM5G5Hy8nPPxEufi5Vqbj9+rqplBgyYW7uuVZKmqZiddx7RwPl7O+XiJc/Fym3U+bMtIUoMMd0lq0EYK9zsnXcCUcT5ezvl4iXPxcptyPjZMz12S1N1GWrlLkjqaunBPclWSHyQ5kuRv13g+ST7bf/7RJG+fRJ3j0mE+PtCfh0eTfC/JpZOocxwGzcWKce9MciLJ+8ZZ37h1mY8k80kOJjmc5DvjrnFcOvw/+Z0kX0vy/f5c3DCJOseqqqbmDdgC/Dfw+8BW4PvAH60acw3wTSDAFcAjk657wvPxp8CF/fevbnU+uszFinH/DnwDeN+k657w98YFwOPAjv7910667gnOxa3Ap/rvzwA/B7ZOuvZRvk3byv1PgCNV9aOqOgZ8Cbh21ZhrgS9Wz8PABUkuHnehYzJwPqrqe1X1i/7dh4FLxlzjuHT53gD4BHAv8NNxFjcBXebj/cC+qnoSoKpanZMuc1HA+UkCnEcv3I+Pt8zxmrZw3wb8ZMX9p/qPrXdMK9b7b/0Qvd9qWjRwLpJsA94L7B1jXZPS5XvjjcCFSRaS7E9y/diqG68uc3EH8BbgaeAQcGNVvTie8iZj2q7ElDUeW72dp8uYVnT+tyZ5F71w/7ORVjQ5XebiM8AtVXWit0BrWpf5OAd4B7ALeDWwmOThqvrhqIsbsy5z8R7gIPBu4A+A+5P8R1U9N+riJmXawv0pYPuK+5fQ+0m73jGt6PRvTfJW4C7g6qr62ZhqG7cuczELfKkf7BcB1yQ5XlVfGU+JY9X1/8qzVfVr4NdJvgtcCrQW7l3m4gbg76vXdD+S5AngzcB/jqfE8Zu2tsx/AW9I8vokW4G/Ae5bNeY+4Pr+rpkrgF9V1TPjLnRMBs5Hkh3APuC6BldkKw2ci6p6fVXtrKqdwJeBjzYa7NDt/8pXgT9Pck6S3wIuB5bHXOc4dJmLJ+n9BkOS1wFvAn401irHbKpW7lV1PMnHgW/T+wv4P1fV4SQf6T+/l94uiGuAI8AL9H4iN6njfHwSeA3wuf6K9Xg1eJKkjnOxaXSZj6paTvIt4FHgReCuqnpsclWPRsfvjduALyQ5RK+Nc0tVtXSmyFfwCFVJatC0tWUkSUNguEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KD/Bx/V7JaW05A1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "\n",
    "def MakeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "m=1\n",
    "b=2\n",
    "x_train, y_train = MakeNoisyData(m,b)\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01991594 -0.03929129 -0.04135054 -0.02225814 -0.00050442 -0.01692079\n",
      " -0.0277063  -0.03913454 -0.04620545 -0.03414563 -0.00657205 -0.02262531\n",
      " -0.00266071 -0.01362088 -0.04947984 -0.04879631 -0.04279347 -0.00437625\n",
      " -0.00648135 -0.04207879], shape=(20,), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.05442544], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(shape=(1,),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(1,),\n",
    "                                initializer='zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.m*inputs+self.b\n",
    "    \n",
    "linear_regression = LinearLayer()\n",
    "print(linear_regression(x_train))\n",
    "print(linear_regression.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 6.4644775\n"
     ]
    }
   ],
   "source": [
    "# Define the mean squared error loss function\n",
    "\n",
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
    "\n",
    "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
    "print(\"Starting loss\", starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss 6.464478\n",
      "Step 1, Loss 4.949445\n",
      "Step 2, Loss 3.790206\n",
      "Step 3, Loss 2.903203\n",
      "Step 4, Loss 2.224504\n",
      "Step 5, Loss 1.705189\n",
      "Step 6, Loss 1.307829\n",
      "Step 7, Loss 1.003784\n",
      "Step 8, Loss 0.771138\n",
      "Step 9, Loss 0.593124\n",
      "Step 10, Loss 0.456913\n",
      "Step 11, Loss 0.352687\n",
      "Step 12, Loss 0.272934\n",
      "Step 13, Loss 0.211908\n",
      "Step 14, Loss 0.165210\n",
      "Step 15, Loss 0.129476\n",
      "Step 16, Loss 0.102131\n",
      "Step 17, Loss 0.081204\n",
      "Step 18, Loss 0.065190\n",
      "Step 19, Loss 0.052933\n",
      "Step 20, Loss 0.043552\n",
      "Step 21, Loss 0.036371\n",
      "Step 22, Loss 0.030874\n",
      "Step 23, Loss 0.026665\n",
      "Step 24, Loss 0.023442\n"
     ]
    }
   ],
   "source": [
    "# Implement a gradient descent training loop for the linear regression model\n",
    "\n",
    "learning_rate = 0.05\n",
    "steps = 25\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = linear_regression(x_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "        \n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
    "    \n",
    "    linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
    "    linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
    "    \n",
    "    print('Step %d, Loss %f' % (i, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:1,  trained m:[0.9773153]\n",
      "b:2,  trained b:[1.9311649]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f44187667f0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned regression model\n",
    "\n",
    "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
    "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
    "\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "\n",
    "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
    "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom layers and model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                initializer='random_normal',\n",
    "                                name='kernel')\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                initializer='zeros',\n",
    "                                name='bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "class MyDropout(Layer):\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "    \n",
    "class MyModel(Model):\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.01834604 0.00809309 0.00956622 0.00578862 0.03876596 0.01357968\n",
      "  0.01779534 0.02777723 0.02250912 0.01746637 0.01129168 0.00467092\n",
      "  0.01233215 0.01088119 0.03797295 0.01372019 0.05698092 0.00586852\n",
      "  0.11614755 0.02858419 0.01613268 0.00321798 0.02392852 0.00687435\n",
      "  0.01125779 0.01559032 0.04879507 0.02847347 0.00773898 0.00401199\n",
      "  0.02733595 0.04521515 0.0124439  0.00973784 0.00793933 0.01750607\n",
      "  0.02325735 0.0285122  0.01604108 0.01463781 0.03011349 0.00303409\n",
      "  0.02275631 0.00958678 0.02369106 0.06403237]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_7 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_4 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_8 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_5 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_9 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(64, 64, 46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reuters dataset and define the class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print(\"Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "\n",
    "print(text_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (8982, 10000)\n",
      "Shape of x_test: (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the forward and backward pass\n",
    "\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 3.303, Accuracy: 0.494\n",
      "Epoch 001: Loss: 1.918, Accuracy: 0.606\n",
      "Epoch 002: Loss: 1.822, Accuracy: 0.657\n",
      "Epoch 003: Loss: 1.783, Accuracy: 0.672\n",
      "Epoch 004: Loss: 1.746, Accuracy: 0.685\n",
      "Epoch 005: Loss: 1.738, Accuracy: 0.692\n",
      "Epoch 006: Loss: 1.729, Accuracy: 0.693\n",
      "Epoch 007: Loss: 1.724, Accuracy: 0.697\n",
      "Epoch 008: Loss: 1.712, Accuracy: 0.697\n",
      "Epoch 009: Loss: 1.703, Accuracy: 0.700\n",
      "Duration :248.853\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    for x, y in train_dataset:\n",
    "        # optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "        \n",
    "    # end epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    print('Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3f}'.format(epoch,\n",
    "                                                               epoch_loss_avg.result(),\n",
    "                                                               epoch_accuracy.result()))\n",
    "    \n",
    "print(\"Duration: {:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object for the test set\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect average loss and accuracy\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.836\n",
      "Test accuracy: 67.453%\n"
     ]
    }
   ],
   "source": [
    "# Loop over the test set and print scores\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value = loss(model, x, y, weight_decay)    \n",
    "    # Compute current loss\n",
    "    epoch_loss_avg(loss_value)  \n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
    "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and accuracy\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: earn\n",
      "     Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Get the model prediction for an example input\n",
    "\n",
    "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
    "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
    "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                initializer='random_normal',\n",
    "                                name='kernel')\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                initializer='zeros',\n",
    "                                name='bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "class MyDropout(Layer):\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "    \n",
    "class MyModel(Model):\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(64, 64, 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the grad function using the @tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 000: Loss: 3.313, Accuracy: 0.479\n",
      "Epoch 001: Loss: 1.937, Accuracy: 0.597\n",
      "Epoch 002: Loss: 1.849, Accuracy: 0.646\n",
      "Epoch 003: Loss: 1.789, Accuracy: 0.679\n",
      "Epoch 004: Loss: 1.762, Accuracy: 0.690\n",
      "Epoch 005: Loss: 1.743, Accuracy: 0.697\n",
      "Epoch 006: Loss: 1.717, Accuracy: 0.703\n",
      "Epoch 007: Loss: 1.714, Accuracy: 0.708\n",
      "Epoch 008: Loss: 1.704, Accuracy: 0.710\n",
      "Epoch 009: Loss: 1.702, Accuracy: 0.709\n",
      "Duration: 283.687\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    for x, y in train_dataset:\n",
    "        # optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "        \n",
    "    # end epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    print('Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3f}'.format(epoch,\n",
    "                                                               epoch_loss_avg.result(),\n",
    "                                                               epoch_accuracy.result()))\n",
    "    \n",
    "print(\"Duration: {:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('grad', 'grad_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as grad_scope:\n",
      "    with tf.GradientTape() as tape:\n",
      "      loss_value = ag__.converted_call(loss, grad_scope.callopts, (model, inputs, targets, wd), None, grad_scope)\n",
      "    do_return = True\n",
      "    retval_ = grad_scope.mark_return_value((loss_value, ag__.converted_call(tape.gradient, grad_scope.callopts, (loss_value, model.trainable_variables), None, grad_scope)))\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf.autograph.to_code to see the generated code\n",
    "\n",
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
