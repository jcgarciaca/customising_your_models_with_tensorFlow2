{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Week 3 - Coding Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk88Aw4NJDIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2a575d-ce38-45d0-ab99-5085532f5841"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "print('GPU name: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n",
            "GPU name: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQb8nVqLJDI5"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### 1.  The IMDb dataset\n",
        " #### 2. Padding and masking sequence data\n",
        " #### 3. The `Embedding` layer\n",
        " #### 4. The Embedding Projector\n",
        " #### 5. Recurrent neural network layers\n",
        " #### 6. Stacked RNNs and the `Bidirectional` wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3PNw3gJDI7"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwqGZQ8WJDJF"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_c1LL5JDJG"
      },
      "source": [
        "# Import imdb\n",
        "\n",
        "import tensorflow.keras.datasets.imdb as imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9jYJCwXJDJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114ccc15-bc9e-4f67-969f-48a6f3f14823"
      },
      "source": [
        "# Download and assign the data set using load_data()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oCnB8UMJDJP"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39RwIt-pJDJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7888d6-158d-43cf-bfa8-a04c4dc45574"
      },
      "source": [
        "# Inspect the type of the data\n",
        "\n",
        "type(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viryy_PDJDJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b64d83-8303-4070-dc6d-5492b56d10a7"
      },
      "source": [
        "# Inspect the shape of the data\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6E6v-FJDJX"
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "\n",
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbEqyjxJDJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89949da-dd04-4264-b1a0-90cc69eea906"
      },
      "source": [
        "# Display the first dataset element output\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAk-PyOgJDJg"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzFxDj-JDJh"
      },
      "source": [
        "# Load the dataset with defaults\n",
        "\n",
        "imdb.load_data(path='imdb.npz', index_from=3)\n",
        "\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGfzZg3JDJv"
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "\n",
        "imdb.load_data(num_words=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMkXgUGaJDJy"
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "\n",
        "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDAFt0FJDJ3"
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "\n",
        "imdb.load_data(maxlen=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-Nr897LorW"
      },
      "source": [
        " # Use '1' as the character that indicates the start of a sequence\n",
        "\n",
        "imdb.load_data(start_char=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBCKKGyJDJ7"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gkaFf6MJDJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11583890-3392-420e-e5bc-fa6c3636f3dc"
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "\n",
        "imdb_word_index = imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUzgAIoKJDKB"
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "\n",
        "index_from = 3\n",
        "imdb_word_index = {key: value + index_from for key, value in imdb_word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCi_QIzJDKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599685d9-43ac-49d4-acd4-c8cc8f76032c"
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "\n",
        "imdb_word_index['simpsonian']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h2tLklgm10l",
        "outputId": "d90bcc03-1408-46b1-d17d-a249632aa437"
      },
      "source": [
        "imdb_word_index['the']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UkZwHiJDKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1ecd2e-5896-4c50-8203-69192dbec187"
      },
      "source": [
        "# View an input sentence\n",
        "\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'film',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'casting',\n",
              " 'location',\n",
              " 'scenery',\n",
              " 'story',\n",
              " 'direction',\n",
              " \"everyone's\",\n",
              " 'really',\n",
              " 'suited',\n",
              " 'the',\n",
              " 'part',\n",
              " 'they',\n",
              " 'played',\n",
              " 'and',\n",
              " 'you',\n",
              " 'could',\n",
              " 'just',\n",
              " 'imagine',\n",
              " 'being',\n",
              " 'there',\n",
              " 'robert',\n",
              " \"redford's\",\n",
              " 'is',\n",
              " 'an',\n",
              " 'amazing',\n",
              " 'actor',\n",
              " 'and',\n",
              " 'now',\n",
              " 'the',\n",
              " 'same',\n",
              " 'being',\n",
              " 'director',\n",
              " \"norman's\",\n",
              " 'father',\n",
              " 'came',\n",
              " 'from',\n",
              " 'the',\n",
              " 'same',\n",
              " 'scottish',\n",
              " 'island',\n",
              " 'as',\n",
              " 'myself',\n",
              " 'so',\n",
              " 'i',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'real',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'this',\n",
              " 'film',\n",
              " 'the',\n",
              " 'witty',\n",
              " 'remarks',\n",
              " 'throughout',\n",
              " 'the',\n",
              " 'film',\n",
              " 'were',\n",
              " 'great',\n",
              " 'it',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'so',\n",
              " 'much',\n",
              " 'that',\n",
              " 'i',\n",
              " 'bought',\n",
              " 'the',\n",
              " 'film',\n",
              " 'as',\n",
              " 'soon',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'released',\n",
              " 'for',\n",
              " 'retail',\n",
              " 'and',\n",
              " 'would',\n",
              " 'recommend',\n",
              " 'it',\n",
              " 'to',\n",
              " 'everyone',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'and',\n",
              " 'the',\n",
              " 'fly',\n",
              " 'fishing',\n",
              " 'was',\n",
              " 'amazing',\n",
              " 'really',\n",
              " 'cried',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " 'it',\n",
              " 'was',\n",
              " 'so',\n",
              " 'sad',\n",
              " 'and',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " 'they',\n",
              " 'say',\n",
              " 'if',\n",
              " 'you',\n",
              " 'cry',\n",
              " 'at',\n",
              " 'a',\n",
              " 'film',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'been',\n",
              " 'good',\n",
              " 'and',\n",
              " 'this',\n",
              " 'definitely',\n",
              " 'was',\n",
              " 'also',\n",
              " 'congratulations',\n",
              " 'to',\n",
              " 'the',\n",
              " 'two',\n",
              " 'little',\n",
              " \"boy's\",\n",
              " 'that',\n",
              " 'played',\n",
              " 'the',\n",
              " \"part's\",\n",
              " 'of',\n",
              " 'norman',\n",
              " 'and',\n",
              " 'paul',\n",
              " 'they',\n",
              " 'were',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'children',\n",
              " 'are',\n",
              " 'often',\n",
              " 'left',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'praising',\n",
              " 'list',\n",
              " 'i',\n",
              " 'think',\n",
              " 'because',\n",
              " 'the',\n",
              " 'stars',\n",
              " 'that',\n",
              " 'play',\n",
              " 'them',\n",
              " 'all',\n",
              " 'grown',\n",
              " 'up',\n",
              " 'are',\n",
              " 'such',\n",
              " 'a',\n",
              " 'big',\n",
              " 'profile',\n",
              " 'for',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'film',\n",
              " 'but',\n",
              " 'these',\n",
              " 'children',\n",
              " 'are',\n",
              " 'amazing',\n",
              " 'and',\n",
              " 'should',\n",
              " 'be',\n",
              " 'praised',\n",
              " 'for',\n",
              " 'what',\n",
              " 'they',\n",
              " 'have',\n",
              " 'done',\n",
              " \"don't\",\n",
              " 'you',\n",
              " 'think',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'story',\n",
              " 'was',\n",
              " 'so',\n",
              " 'lovely',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'true',\n",
              " 'and',\n",
              " 'was',\n",
              " \"someone's\",\n",
              " 'life',\n",
              " 'after',\n",
              " 'all',\n",
              " 'that',\n",
              " 'was',\n",
              " 'shared',\n",
              " 'with',\n",
              " 'us',\n",
              " 'all']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2ID8wRJDKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b79218-9239-4b48-9f5f-875f8521d3c9"
      },
      "source": [
        "# Get the sentiment value\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPUtmz-JDKZ"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UggNd-8VLgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb38308-840e-4639-b88f-9a8ecc265d47"
      },
      "source": [
        "# Load the imdb data set\n",
        "\n",
        "import tensorflow.keras.datasets.imdb as imdb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqWhXi-JDKa"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWULtJ7CJDKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2991ea7f-3f44-420a-c13b-4a402b99ff9e"
      },
      "source": [
        "# Inspect the input data shape\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOts_k01JDKh"
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen\n",
        "\n",
        "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding='post', truncating='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNPiMGwDJDKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a3822e-9c7c-4140-d23c-7d02f975ea73"
      },
      "source": [
        "# Inspect the output data shape\n",
        "\n",
        "padded_x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt56letJDKn"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdoMdifYJDKo"
      },
      "source": [
        "# Import numpy \n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8LjX9QaJDKr"
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "\n",
        "padded_x_train = np.expand_dims(padded_x_train, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NJdAyltpVHv",
        "outputId": "7d53a6a7-bc59-4da9-92ab-48c25297eec3"
      },
      "source": [
        "padded_x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrgXbDrJDKt"
      },
      "source": [
        "# Create a Masking layer \n",
        "\n",
        "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
        "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkSzdHwJDKw"
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "\n",
        "masked_x_train = masking_layer(tf_x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuStn9s0JDK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5edc16-0fe3-451d-d6dd-2a6f020b7c17"
      },
      "source": [
        "# Look at the dataset\n",
        "\n",
        "masked_x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(300, 1), dtype=float32, numpy=\n",
              "array([[1.0000e+00],\n",
              "       [1.4000e+01],\n",
              "       [2.2000e+01],\n",
              "       [1.6000e+01],\n",
              "       [4.3000e+01],\n",
              "       [5.3000e+02],\n",
              "       [9.7300e+02],\n",
              "       [1.6220e+03],\n",
              "       [1.3850e+03],\n",
              "       [6.5000e+01],\n",
              "       [4.5800e+02],\n",
              "       [4.4680e+03],\n",
              "       [6.6000e+01],\n",
              "       [3.9410e+03],\n",
              "       [4.0000e+00],\n",
              "       [1.7300e+02],\n",
              "       [3.6000e+01],\n",
              "       [2.5600e+02],\n",
              "       [5.0000e+00],\n",
              "       [2.5000e+01],\n",
              "       [1.0000e+02],\n",
              "       [4.3000e+01],\n",
              "       [8.3800e+02],\n",
              "       [1.1200e+02],\n",
              "       [5.0000e+01],\n",
              "       [6.7000e+02],\n",
              "       [2.2665e+04],\n",
              "       [9.0000e+00],\n",
              "       [3.5000e+01],\n",
              "       [4.8000e+02],\n",
              "       [2.8400e+02],\n",
              "       [5.0000e+00],\n",
              "       [1.5000e+02],\n",
              "       [4.0000e+00],\n",
              "       [1.7200e+02],\n",
              "       [1.1200e+02],\n",
              "       [1.6700e+02],\n",
              "       [2.1631e+04],\n",
              "       [3.3600e+02],\n",
              "       [3.8500e+02],\n",
              "       [3.9000e+01],\n",
              "       [4.0000e+00],\n",
              "       [1.7200e+02],\n",
              "       [4.5360e+03],\n",
              "       [1.1110e+03],\n",
              "       [1.7000e+01],\n",
              "       [5.4600e+02],\n",
              "       [3.8000e+01],\n",
              "       [1.3000e+01],\n",
              "       [4.4700e+02],\n",
              "       [4.0000e+00],\n",
              "       [1.9200e+02],\n",
              "       [5.0000e+01],\n",
              "       [1.6000e+01],\n",
              "       [6.0000e+00],\n",
              "       [1.4700e+02],\n",
              "       [2.0250e+03],\n",
              "       [1.9000e+01],\n",
              "       [1.4000e+01],\n",
              "       [2.2000e+01],\n",
              "       [4.0000e+00],\n",
              "       [1.9200e+03],\n",
              "       [4.6130e+03],\n",
              "       [4.6900e+02],\n",
              "       [4.0000e+00],\n",
              "       [2.2000e+01],\n",
              "       [7.1000e+01],\n",
              "       [8.7000e+01],\n",
              "       [1.2000e+01],\n",
              "       [1.6000e+01],\n",
              "       [4.3000e+01],\n",
              "       [5.3000e+02],\n",
              "       [3.8000e+01],\n",
              "       [7.6000e+01],\n",
              "       [1.5000e+01],\n",
              "       [1.3000e+01],\n",
              "       [1.2470e+03],\n",
              "       [4.0000e+00],\n",
              "       [2.2000e+01],\n",
              "       [1.7000e+01],\n",
              "       [5.1500e+02],\n",
              "       [1.7000e+01],\n",
              "       [1.2000e+01],\n",
              "       [1.6000e+01],\n",
              "       [6.2600e+02],\n",
              "       [1.8000e+01],\n",
              "       [1.9193e+04],\n",
              "       [5.0000e+00],\n",
              "       [6.2000e+01],\n",
              "       [3.8600e+02],\n",
              "       [1.2000e+01],\n",
              "       [8.0000e+00],\n",
              "       [3.1600e+02],\n",
              "       [8.0000e+00],\n",
              "       [1.0600e+02],\n",
              "       [5.0000e+00],\n",
              "       [4.0000e+00],\n",
              "       [2.2230e+03],\n",
              "       [5.2440e+03],\n",
              "       [1.6000e+01],\n",
              "       [4.8000e+02],\n",
              "       [6.6000e+01],\n",
              "       [3.7850e+03],\n",
              "       [3.3000e+01],\n",
              "       [4.0000e+00],\n",
              "       [1.3000e+02],\n",
              "       [1.2000e+01],\n",
              "       [1.6000e+01],\n",
              "       [3.8000e+01],\n",
              "       [6.1900e+02],\n",
              "       [5.0000e+00],\n",
              "       [2.5000e+01],\n",
              "       [1.2400e+02],\n",
              "       [5.1000e+01],\n",
              "       [3.6000e+01],\n",
              "       [1.3500e+02],\n",
              "       [4.8000e+01],\n",
              "       [2.5000e+01],\n",
              "       [1.4150e+03],\n",
              "       [3.3000e+01],\n",
              "       [6.0000e+00],\n",
              "       [2.2000e+01],\n",
              "       [1.2000e+01],\n",
              "       [2.1500e+02],\n",
              "       [2.8000e+01],\n",
              "       [7.7000e+01],\n",
              "       [5.2000e+01],\n",
              "       [5.0000e+00],\n",
              "       [1.4000e+01],\n",
              "       [4.0700e+02],\n",
              "       [1.6000e+01],\n",
              "       [8.2000e+01],\n",
              "       [1.0311e+04],\n",
              "       [8.0000e+00],\n",
              "       [4.0000e+00],\n",
              "       [1.0700e+02],\n",
              "       [1.1700e+02],\n",
              "       [5.9520e+03],\n",
              "       [1.5000e+01],\n",
              "       [2.5600e+02],\n",
              "       [4.0000e+00],\n",
              "       [3.1050e+04],\n",
              "       [7.0000e+00],\n",
              "       [3.7660e+03],\n",
              "       [5.0000e+00],\n",
              "       [7.2300e+02],\n",
              "       [3.6000e+01],\n",
              "       [7.1000e+01],\n",
              "       [4.3000e+01],\n",
              "       [5.3000e+02],\n",
              "       [4.7600e+02],\n",
              "       [2.6000e+01],\n",
              "       [4.0000e+02],\n",
              "       [3.1700e+02],\n",
              "       [4.6000e+01],\n",
              "       [7.0000e+00],\n",
              "       [4.0000e+00],\n",
              "       [1.2118e+04],\n",
              "       [1.0290e+03],\n",
              "       [1.3000e+01],\n",
              "       [1.0400e+02],\n",
              "       [8.8000e+01],\n",
              "       [4.0000e+00],\n",
              "       [3.8100e+02],\n",
              "       [1.5000e+01],\n",
              "       [2.9700e+02],\n",
              "       [9.8000e+01],\n",
              "       [3.2000e+01],\n",
              "       [2.0710e+03],\n",
              "       [5.6000e+01],\n",
              "       [2.6000e+01],\n",
              "       [1.4100e+02],\n",
              "       [6.0000e+00],\n",
              "       [1.9400e+02],\n",
              "       [7.4860e+03],\n",
              "       [1.8000e+01],\n",
              "       [4.0000e+00],\n",
              "       [2.2600e+02],\n",
              "       [2.2000e+01],\n",
              "       [2.1000e+01],\n",
              "       [1.3400e+02],\n",
              "       [4.7600e+02],\n",
              "       [2.6000e+01],\n",
              "       [4.8000e+02],\n",
              "       [5.0000e+00],\n",
              "       [1.4400e+02],\n",
              "       [3.0000e+01],\n",
              "       [5.5350e+03],\n",
              "       [1.8000e+01],\n",
              "       [5.1000e+01],\n",
              "       [3.6000e+01],\n",
              "       [2.8000e+01],\n",
              "       [2.2400e+02],\n",
              "       [9.2000e+01],\n",
              "       [2.5000e+01],\n",
              "       [1.0400e+02],\n",
              "       [4.0000e+00],\n",
              "       [2.2600e+02],\n",
              "       [6.5000e+01],\n",
              "       [1.6000e+01],\n",
              "       [3.8000e+01],\n",
              "       [1.3340e+03],\n",
              "       [8.8000e+01],\n",
              "       [1.2000e+01],\n",
              "       [1.6000e+01],\n",
              "       [2.8300e+02],\n",
              "       [5.0000e+00],\n",
              "       [1.6000e+01],\n",
              "       [4.4720e+03],\n",
              "       [1.1300e+02],\n",
              "       [1.0300e+02],\n",
              "       [3.2000e+01],\n",
              "       [1.5000e+01],\n",
              "       [1.6000e+01],\n",
              "       [5.3450e+03],\n",
              "       [1.9000e+01],\n",
              "       [1.7800e+02],\n",
              "       [3.2000e+01],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00],\n",
              "       [0.0000e+00]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54DVLx4JDK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4edb772-b34c-4be4-d4e2-e144c32d2ae5"
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "\n",
        "masked_x_train._keras_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5rD5ZcJDK_"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkBOM8mJDLA"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-esPcdDJDLJ"
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim, output_dim, input_length\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf3B6HamJDLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b4a344-41c0-4576-c3a5-c4677e153c5c"
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "\n",
        "sequence_of_indices = tf.constant([[[0], [1], [5], [500]]])\n",
        "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
        "sequence_of_embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
              "array([[[[ 0.0250255 , -0.02126033,  0.03991226, -0.00748583,\n",
              "          -0.03666276, -0.02920407,  0.04028619,  0.04642922,\n",
              "           0.03759818, -0.03417207,  0.03822808,  0.0114421 ,\n",
              "          -0.03697283, -0.02312614,  0.01459697, -0.02751688]],\n",
              "\n",
              "        [[-0.04568798, -0.00534292,  0.01415421, -0.0322988 ,\n",
              "           0.03015688,  0.0400962 ,  0.0343065 , -0.00538914,\n",
              "           0.02835311, -0.02426771, -0.02757987, -0.04145324,\n",
              "          -0.04415271, -0.01346062,  0.02139914, -0.00642227]],\n",
              "\n",
              "        [[ 0.04820662, -0.02861469,  0.04124482, -0.01027117,\n",
              "          -0.03577543, -0.00584869,  0.00108083,  0.00272635,\n",
              "          -0.0079003 , -0.03334834, -0.01184677, -0.03767923,\n",
              "          -0.02948107,  0.03242772,  0.00967711,  0.03048519]],\n",
              "\n",
              "        [[-0.0444218 , -0.03271331, -0.00352544, -0.00694091,\n",
              "           0.00443875, -0.04903904,  0.00641724, -0.04933807,\n",
              "          -0.0143819 , -0.00034203,  0.04762414,  0.0369609 ,\n",
              "           0.01584052,  0.03794025,  0.01272339,  0.02242079]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ualmsaPpJDLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7ca68e-2410-4a3a-fcac-9d821d1df559"
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "\n",
        "embedding_layer.get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.0250255 , -0.02126033,  0.03991226, ..., -0.02312614,\n",
              "         0.01459697, -0.02751688],\n",
              "       [-0.04568798, -0.00534292,  0.01415421, ..., -0.01346062,\n",
              "         0.02139914, -0.00642227],\n",
              "       [ 0.04112849,  0.02720164, -0.01860169, ...,  0.01689072,\n",
              "         0.0321471 , -0.03098547],\n",
              "       ...,\n",
              "       [ 0.04395029,  0.0347135 ,  0.0068198 , ...,  0.02703064,\n",
              "         0.04510203, -0.02270099],\n",
              "       [ 0.03600897,  0.00114552,  0.02667591, ..., -0.02437919,\n",
              "        -0.02046038,  0.016516  ],\n",
              "       [-0.0444218 , -0.03271331, -0.00352544, ...,  0.03794025,\n",
              "         0.01272339,  0.02242079]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wadlt3AJDLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b7a417-57d3-480c-daba-e8087991adcd"
      },
      "source": [
        "# Get the embedding for the 14th index\n",
        "\n",
        "embedding_layer.get_weights()[0][14, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02448838,  0.0432871 , -0.04558095,  0.00266565, -0.0426646 ,\n",
              "       -0.0370836 , -0.02404751,  0.04717355,  0.03429213,  0.02817028,\n",
              "        0.00610013,  0.02016476,  0.00831809, -0.01077356,  0.00460368,\n",
              "        0.00789315], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuhReOm9xF7"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKYwKT_I-H2O"
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "\n",
        "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16, mask_zero=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiosbkHNrNvS",
        "outputId": "e4ffb296-93ed-4f2c-bf18-72ca1feadbce"
      },
      "source": [
        "sequence_of_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1), dtype=int32, numpy=\n",
              "array([[[  0],\n",
              "        [  1],\n",
              "        [  5],\n",
              "        [500]]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hc1zx6A-H6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5fd61c-215f-4782-956a-7a89ca673364"
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "\n",
        "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
        "masked_sequence_of_embeddings._keras_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1), dtype=bool, numpy=\n",
              "array([[[False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUG6LF1MJDL0"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zna3TCoTAu00"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPKYrlepAxPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295f57f6-42cb-4470-ff43-9477f7c78989"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBAX9ENDBFFE"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5qBbDDBIdn"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpymnb2BIiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175ea7d0-7390-4b56-b84e-c0f53357f26c"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EtU2vK0BLts"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIEIdRBSxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993dcf68-fbaa-48bd-9674-2db408a8f541"
      },
      "source": [
        "# Get the word index\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2fp10YBS6T"
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cquirCA8BS99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13349549-763d-4f44-eba2-b9219b270200"
      },
      "source": [
        "# View the first dataset example sentence\n",
        "\n",
        "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'a',\n",
              " 'great',\n",
              " 'fan',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'and',\n",
              " 'have',\n",
              " 'everything',\n",
              " 'that',\n",
              " \"he's\",\n",
              " 'made',\n",
              " 'on',\n",
              " 'dvd',\n",
              " 'except',\n",
              " 'for',\n",
              " 'hotel',\n",
              " 'room',\n",
              " 'the',\n",
              " '2',\n",
              " 'hour',\n",
              " 'twin',\n",
              " 'peaks',\n",
              " 'movie',\n",
              " 'so',\n",
              " 'when',\n",
              " 'i',\n",
              " 'found',\n",
              " 'out',\n",
              " 'about',\n",
              " 'this',\n",
              " 'i',\n",
              " 'immediately',\n",
              " 'grabbed',\n",
              " 'it',\n",
              " 'and',\n",
              " 'and',\n",
              " 'what',\n",
              " 'is',\n",
              " 'this',\n",
              " \"it's\",\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'drawn',\n",
              " 'black',\n",
              " 'and',\n",
              " 'white',\n",
              " 'cartoons',\n",
              " 'that',\n",
              " 'are',\n",
              " 'loud',\n",
              " 'and',\n",
              " 'foul',\n",
              " 'mouthed',\n",
              " 'and',\n",
              " 'unfunny',\n",
              " 'maybe',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " \"what's\",\n",
              " 'good',\n",
              " 'but',\n",
              " 'maybe',\n",
              " 'this',\n",
              " 'is',\n",
              " 'just',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'crap',\n",
              " 'that',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'public',\n",
              " 'under',\n",
              " 'the',\n",
              " 'name',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'to',\n",
              " 'make',\n",
              " 'a',\n",
              " 'few',\n",
              " 'bucks',\n",
              " 'too',\n",
              " 'let',\n",
              " 'me',\n",
              " 'make',\n",
              " 'it',\n",
              " 'clear',\n",
              " 'that',\n",
              " 'i',\n",
              " \"didn't\",\n",
              " 'care',\n",
              " 'about',\n",
              " 'the',\n",
              " 'foul',\n",
              " 'language',\n",
              " 'part',\n",
              " 'but',\n",
              " 'had',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'because',\n",
              " 'my',\n",
              " 'neighbors',\n",
              " 'might',\n",
              " 'have',\n",
              " 'all',\n",
              " 'in',\n",
              " 'all',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'highly',\n",
              " 'disappointing',\n",
              " 'release',\n",
              " 'and',\n",
              " 'may',\n",
              " 'well',\n",
              " 'have',\n",
              " 'just',\n",
              " 'been',\n",
              " 'left',\n",
              " 'in',\n",
              " 'the',\n",
              " 'box',\n",
              " 'set',\n",
              " 'as',\n",
              " 'a',\n",
              " 'curiosity',\n",
              " 'i',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'you',\n",
              " \"don't\",\n",
              " 'spend',\n",
              " 'your',\n",
              " 'money',\n",
              " 'on',\n",
              " 'this',\n",
              " '2',\n",
              " 'out',\n",
              " 'of',\n",
              " '10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrE0rpCVJDL1"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPUfv9kjJDL1"
      },
      "source": [
        "# Get the maximum token value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO0CkecjJDL5"
      },
      "source": [
        "# Specify an embedding dimension\n",
        "\n",
        "embedding_dim = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBZOlp3JDL7"
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(input_dim=max_index_value + 1, output_dim=embedding_dim, mask_zero=False),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9qhtlPJDL9"
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "\n",
        "review_sequence = tf.keras.Input((None,))\n",
        "embedding_sequence = tf.keras.layers.Embedding(input_dim=max_index_value + 1, output_dim=embedding_dim)(review_sequence)\n",
        "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
        "positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
        "\n",
        "model = tf.keras.Model(inputs=review_sequence, outputs=positive_probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf6oaEvTCKxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3caf3b-ec10-401c-d22e-e30d53c7f67a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrX43gwPJDL-"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVfI_1EoJDL_"
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvR-O7wGJDMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850bc6a0-749f-4910-83d1-71bb3de66a8b"
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 9s 8ms/step - loss: 0.6917 - accuracy: 0.5275 - val_loss: 0.6835 - val_accuracy: 0.5484\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6761 - accuracy: 0.6536 - val_loss: 0.6467 - val_accuracy: 0.7172\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6379 - accuracy: 0.7340 - val_loss: 0.5985 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5843 - accuracy: 0.7944 - val_loss: 0.5534 - val_accuracy: 0.7609\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5356 - accuracy: 0.8151 - val_loss: 0.5059 - val_accuracy: 0.7984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ind0d_gvJDMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "4de2580c-0940-4563-d35f-59bca5de14c5"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHcNqGnWJDMH"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVP4G9X0JDMH"
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "\n",
        "weights = model.layers[1].get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHd29nfZJDMJ"
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "out_v = io.open(path.join('drive', 'MyDrive', 'Colab Notebooks', 'vecs.tsv'), 'w', encoding='utf-8')\n",
        "out_m = io.open(path.join('drive', 'MyDrive', 'Colab Notebooks', 'meta.tsv'), 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in imdb_word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ti4kMquJDML"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hrm6Q2jJDMM"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7uSwkQJDMR"
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "\n",
        "simplernn_layer = tf.keras.layers.SimpleRNN(16)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_YJUyrEJDMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c090103-2bf1-439a-90d3-bbe0ae861290"
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "\n",
        "sequence = tf.constant([[[1., 1.], [2., 2.], [56., -100.]]])\n",
        "layer_output = simplernn_layer(sequence)\n",
        "layer_output"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[ 0.99965805,  0.99999976, -0.99999976,  0.99999976, -0.99999976,\n",
              "         0.99999976,  0.99999976, -0.99999976,  0.99999976, -0.99999976,\n",
              "         0.99999976,  0.99999976, -0.99999976,  0.9816306 , -0.99999976,\n",
              "         0.9971239 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_rwdZtmJDMV"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvAtycIpH1aA"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rJuSFmJDMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e14a685-003e-4de9-f907-b9197c7f0885"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=150)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwUHcFKwH4wh"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfyqmfOXJDMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6ee9d6-96fc-4db9-d7b6-be18e6de97de"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7y1e-xJDMd"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tym76m2dIVOZ"
      },
      "source": [
        "# Get the maximum index value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "embedding_dim = 16"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tO953-oJDMd"
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=max_index_value, output_dim=embedding_dim, mask_zero=True),\n",
        "                                    tf.keras.layers.LSTM(16),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v076l5CUJDMf"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRXW5mPJDMg"
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216PeHZFJDMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6ca54d-0a46-4217-f305-2bed6079dc7b"
      },
      "source": [
        "# Fit the model and save its training history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "291/291 [==============================] - 93s 310ms/step - loss: 0.6256 - accuracy: 0.6223\n",
            "Epoch 2/3\n",
            "291/291 [==============================] - 90s 310ms/step - loss: 0.2685 - accuracy: 0.9064\n",
            "Epoch 3/3\n",
            "291/291 [==============================] - 90s 309ms/step - loss: 0.1547 - accuracy: 0.9509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVXF1TSJDMj"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9VW07lJDMk"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAyEd6wJDMm"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9CHYLiJDMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d6a162-9786-47ff-c68c-633abfe5d5e2"
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "\n",
        "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_test[0] if index > 2]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['please',\n",
              " 'give',\n",
              " 'this',\n",
              " 'one',\n",
              " 'a',\n",
              " 'miss',\n",
              " 'br',\n",
              " 'br',\n",
              " 'and',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'cast',\n",
              " 'rendered',\n",
              " 'terrible',\n",
              " 'performances',\n",
              " 'the',\n",
              " 'show',\n",
              " 'is',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'flat',\n",
              " 'br',\n",
              " 'br',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " 'how',\n",
              " 'michael',\n",
              " 'madison',\n",
              " 'could',\n",
              " 'have',\n",
              " 'allowed',\n",
              " 'this',\n",
              " 'one',\n",
              " 'on',\n",
              " 'his',\n",
              " 'plate',\n",
              " 'he',\n",
              " 'almost',\n",
              " 'seemed',\n",
              " 'to',\n",
              " 'know',\n",
              " 'this',\n",
              " \"wasn't\",\n",
              " 'going',\n",
              " 'to',\n",
              " 'work',\n",
              " 'out',\n",
              " 'and',\n",
              " 'his',\n",
              " 'performance',\n",
              " 'was',\n",
              " 'quite',\n",
              " 'so',\n",
              " 'all',\n",
              " 'you',\n",
              " 'madison',\n",
              " 'fans',\n",
              " 'give',\n",
              " 'this',\n",
              " 'a',\n",
              " 'miss']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blf6in2dJDMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6880e5e4-a37c-4ac1-aed7-164857c0dc90"
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "\n",
        "model.predict(x_test[None, 0, :])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03076338]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCyKBsZHJDMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e6fc67-c4c5-442b-b4a1-d9fda1c0d88a"
      },
      "source": [
        "# Get the corresponding label\n",
        "\n",
        "y_test[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpaI83PlJDMv"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qr4kOevKRt8"
      },
      "source": [
        "#### Load and transform the IMDb review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06LdJiXKRt9"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjA8JlQVKRuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c46ff45-2922-47f0-e65a-0aebad985077"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words=5000, maxlen=250)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iBFGx9_KRuD"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lcV0UGKRuF"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "imdb_word_index = get_imdb_word_index(num_words=5000)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_Vv9-5JDM1"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Sy-gMyLLEI"
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "embedding_dim = 16"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yWIAFdJDM1"
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=max_index_value, output_dim=embedding_dim, mask_zero=True),\n",
        "                                    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "                                    tf.keras.layers.LSTM(32),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-34ZWvRJDM3"
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=max_index_value, output_dim=embedding_dim, mask_zero=True),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8), merge_mode='sum',\n",
        "                                                                  backward_layer=tf.keras.layers.GRU(8, go_backwards=True)),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpOIOCmJDM4"
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=max_index_value, output_dim=embedding_dim, mask_zero=True),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8, return_sequences=True), merge_mode='concat'),\n",
        "                                    tf.keras.layers.GRU(8),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3srEhqCJDM7"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Dy_C6-JDM7"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er8atiBoJDM9"
      },
      "source": [
        "# Train the model, saving its history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=3, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLOLtBKwJDNA"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}